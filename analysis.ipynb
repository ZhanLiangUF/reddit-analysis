{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('t1_cqug90g', 't5_378oi', 0), ('t1_cqug90h', 't5_2qo4s', 0.423), ('t1_cqug90i', 't5_2cneq', 0), ('t1_cqug90j', 't5_2qh1i', 0), ('t1_cqug90k', 't5_2qh1i', 0)]\n",
      "[[ 0.       0.       0.       0.     ]\n",
      " [-0.10575 -0.10575  0.31725 -0.10575]\n",
      " [ 0.       0.       0.       0.     ]\n",
      " [ 0.       0.       0.       0.     ]\n",
      " [ 0.       0.       0.       0.     ]]\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Tokenization and sentiment analysis\n",
    "\"\"\"\n",
    "# conn.cursor().execute(\"\"\"DROP TABLE linkusersentimenttosubreddit\"\"\")\n",
    "sql_create_linkusersentimenttosubreddit_table = \"\"\" CREATE TABLE IF NOT EXISTS linkusersentimenttosubreddit (\n",
    "                                        userid text,\n",
    "                                        subredditid text,\n",
    "                                        rating integer\n",
    "                                    ); \"\"\"\n",
    "conn.cursor().execute(sql_create_linkusersentimenttosubreddit_table)\n",
    "\n",
    "\"\"\"\n",
    "The snippet below is ran onced - to insert data into a new table\n",
    "\"\"\"\n",
    "\n",
    "# sid = SentimentIntensityAnalyzer()\n",
    "# for comment in reddit_comments:\n",
    "#     array_of_sentences = nltk.sent_tokenize(comment[2])\n",
    "#     comment_sentiment = 0\n",
    "#     for sentence in array_of_sentences:\n",
    "#         ss = sid.polarity_scores(sentence)\n",
    "#         array_of_tokenized_values = []\n",
    "#         comment_sentiment += ss['pos']  \n",
    "#     conn.cursor().execute(\"INSERT INTO linkusersentimenttosubreddit VALUES (?, ?, ?)\", (comment[1], comment[0], comment_sentiment))\n",
    "#     conn.commit()\n",
    "newtable = conn.cursor().execute(\"SELECT * from linkusersentimenttosubreddit\").fetchall()\n",
    "print(newtable)\n",
    "comments_df = pd.DataFrame(newtable, columns = ['UserID', 'SubredditID', 'Rating'])\n",
    "R_df = comments_df.pivot(index = 'UserID', columns ='SubredditID', values = 'Rating').fillna(0)\n",
    "R_df.head()\n",
    "\n",
    "# # \"\"\"\n",
    "# # convert to a numpy array\n",
    "# # \"\"\"\n",
    "R = R_df.as_matrix()\n",
    "# ratings_mean = np.mean(R)\n",
    "# R_demeaned = R - ratings_mean.reshape(-1, 1)\n",
    "# print(R_demeaned)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('t5_378oi', 't1_cqug90g', 'くそ\\n読みたいが買ったら負けな気がする\\n図書館に出ねーかな')"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import sqlite3\n",
    "from sqlite3 import Error\n",
    "import nltk\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from scipy.sparse.linalg import svds\n",
    "\n",
    "\n",
    "def create_connection(db_file):\n",
    "    try:\n",
    "        conn = sqlite3.connect(db_file)\n",
    "        return conn\n",
    "    except Error as e:\n",
    "        print(e)\n",
    " \n",
    "    return None\n",
    "\n",
    "conn = create_connection(\"database.sqlite\")\n",
    "    \n",
    "reddit_comments = conn.cursor().execute(\"SELECT subreddit_id, name, body  from May2015 LIMIT 5\").fetchall()\n",
    "reddit_comments[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nAlright now to perform svd\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Alright now to perform svd\n",
    "\"\"\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
