{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('t5_378oi', 't1_cqug90g', 'くそ\\n読みたいが買ったら負けな気がする\\n図書館に出ねーかな')"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import sqlite3\n",
    "from sqlite3 import Error\n",
    "import nltk\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "\n",
    "try:\n",
    "    conn = sqlite3.connect(\"./database.sqlite\")\n",
    "except Error as e:\n",
    "    print(e)\n",
    "\n",
    "\n",
    "    \n",
    "reddit_comments = conn.cursor().execute(\"SELECT subreddit_id, name, body  from May2015 LIMIT 5\").fetchall()\n",
    "reddit_comments[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('t5_378oi', 't1_cqug90g', 'くそ\\n読みたいが買ったら負けな気がする\\n図書館に出ねーかな')\n",
      "['くそ\\n読みたいが買ったら負けな気がする\\n図書館に出ねーかな']\n",
      "compound: 0.0, \n",
      "neg: 0.0, \n",
      "neu: 1.0, \n",
      "pos: 0.0, \n",
      "('t5_2qo4s', 't1_cqug90h', \"gg this one's over. off to watch the NFL draft I guess\")\n",
      "[\"gg this one's over.\", 'off to watch the NFL draft I guess']\n",
      "compound: 0.296, \n",
      "neg: 0.0, \n",
      "neu: 0.577, \n",
      "pos: 0.423, \n",
      "compound: 0.0, \n",
      "neg: 0.0, \n",
      "neu: 1.0, \n",
      "pos: 0.0, \n",
      "('t5_2cneq', 't1_cqug90i', \"Are you really implying we return to those times or anywhere near that political environment?  If so, you won't have much luck selling the American people on that governance concept without ushering in American Revolution 2.0.\")\n",
      "['Are you really implying we return to those times or anywhere near that political environment?', \"If so, you won't have much luck selling the American people on that governance concept without ushering in American Revolution 2.0.\"]\n",
      "compound: 0.0, \n",
      "neg: 0.0, \n",
      "neu: 1.0, \n",
      "pos: 0.0, \n",
      "compound: -0.357, \n",
      "neg: 0.11, \n",
      "neu: 0.89, \n",
      "pos: 0.0, \n",
      "('t5_2qh1i', 't1_cqug90j', \"No one has a European accent either  because it doesn't exist. There are accents from Europe but not a European accent.\")\n",
      "[\"No one has a European accent either  because it doesn't exist.\", 'There are accents from Europe but not a European accent.']\n",
      "compound: -0.296, \n",
      "neg: 0.196, \n",
      "neu: 0.804, \n",
      "pos: 0.0, \n",
      "compound: 0.0, \n",
      "neg: 0.0, \n",
      "neu: 1.0, \n",
      "pos: 0.0, \n",
      "('t5_2qh1i', 't1_cqug90k', 'That the kid \"..reminds me of Kevin.\"   so sad :-(')\n",
      "['That the kid \"..reminds me of Kevin.\"', 'so sad :-(']\n",
      "compound: 0.0, \n",
      "neg: 0.0, \n",
      "neu: 1.0, \n",
      "pos: 0.0, \n",
      "compound: -0.7328, \n",
      "neg: 0.861, \n",
      "neu: 0.139, \n",
      "pos: 0.0, \n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Now that I have data in tuple format, how do i clean up the data?\n",
    "Next step is to tokenize -> transform comments to an actual value of some sort.\n",
    "\"\"\"\n",
    "sid = SentimentIntensityAnalyzer()\n",
    "for comment in reddit_comments:\n",
    "    print(comment)\n",
    "    array_of_sentences = nltk.sent_tokenize(comment[2])\n",
    "    for sentence in array_of_sentences:\n",
    "        ss = sid.polarity_scores(sentence)\n",
    "        array_of_tokenized_values = []\n",
    "        for k in sorted(ss):\n",
    "            print('{0}: {1}, '.format(k, ss[k]), end='')\n",
    "            print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Alright now have to perform sentiment analysis\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
